{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.set_printoptions(precision=5)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Possible Kuhn Poker Games\n",
    "Player 1    Player 2    Player 1    Payoff\n",
    "pass        pass                    +1 to player with higher card\n",
    "pass        bet         pass        +1 to player 2\n",
    "pass        bet         bet         +2 to player with higher card\n",
    "bet         pass                    +1 to player 1\n",
    "bet         bet +2                  to player with higher card\n",
    "\n",
    "12 Informationsets:\n",
    "Initial state\n",
    "    King\n",
    "    Queen\n",
    "    Jack\n",
    "\n",
    "1st option\n",
    "    King    p1 pass\n",
    "    King    p1 bet\n",
    "    Queen   p1 pass\n",
    "    Queen   p1 bet\n",
    "    Jack    p1 pass\n",
    "    Jack    p1 bet\n",
    "\n",
    "2nd option\n",
    "    King    p1 bet p2 bet \n",
    "    Queen   p1 bet p2 bet\n",
    "    Jack    p1 bet p2 bet\n",
    "\"\"\"\n",
    "\n",
    "CARDS = [\"J\", \"Q\", \"K\"]\n",
    "ACTIONS = [\"PASS\", \"BET\"]\n",
    "J, Q, K = 0, 1, 2\n",
    "PASS, BET = 0, 1\n",
    "NUM_ACTIONS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, card, history, num_actions):\n",
    "        # card and history are only used for node state printing in __repr__\n",
    "        self.card = card\n",
    "        self.history = history\n",
    "\n",
    "        self.num_actions = num_actions\n",
    "        self.regret_sum = np.zeros(num_actions)\n",
    "        self.strategy_sum = np.zeros(num_actions)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return CARDS[self.card] + \" \" + str([ACTIONS[h] for h in self.history]) + \" \" + str([ACTIONS[i] + \" \" + format(strat*100, '.0f') + \"%\" for i, strat in enumerate(self.normalize(self.strategy_sum))])\n",
    "\n",
    "    def normalize(self, value):\n",
    "        normalizing_sum = np.sum(value)\n",
    "        if normalizing_sum > 0:\n",
    "            return value / normalizing_sum\n",
    "        return np.ones(self.num_actions) / self.num_actions\n",
    "\n",
    "    def get_strategy(self):\n",
    "        return self.normalize(np.maximum(self.regret_sum, 0))\n",
    "    \n",
    "    def get_action(self):\n",
    "        strategy = self.normalize(self.strategy_sum)\n",
    "        return np.searchsorted(np.cumsum(strategy), np.random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_terminal_payout(history, player_card, opponent_card):\n",
    "    if len(history) < 2:\n",
    "        return None\n",
    "    \n",
    "    terminal_pass = history[-1] == PASS\n",
    "    showdown_payout = 1 if player_card > opponent_card else -1\n",
    "    if terminal_pass:\n",
    "        if history[0] == history[1] == PASS:\n",
    "            return showdown_payout\n",
    "        return 1\n",
    "    \n",
    "    double_bet = history[-1] == history[-2] == BET\n",
    "    if double_bet:\n",
    "        return showdown_payout * 2\n",
    "    \n",
    "    return None\n",
    "\n",
    "def get_node(nodes, history, player_card) -> Node:\n",
    "    info_set_hash = int(player_card + np.sum([(info+1) * (i+2)**NUM_ACTIONS for i, info in enumerate(history)]))\n",
    "    node = nodes.get(info_set_hash, Node(player_card, history, NUM_ACTIONS))\n",
    "    nodes[info_set_hash] = node\n",
    "    return node\n",
    "\n",
    "def counter_factual_regret(nodes, cards, history, realization_weight_p0, realization_weight_p1):\n",
    "    player = len(history) % 2\n",
    "    opponent = 1 - player\n",
    "\n",
    "    payout = get_terminal_payout(history, cards[player], cards[opponent])\n",
    "    if payout is not None:\n",
    "        return payout\n",
    "    \n",
    "    player0_turn = player == 0\n",
    "\n",
    "    node = get_node(nodes, history, cards[player])\n",
    "    strategy = node.get_strategy()\n",
    "    node.strategy_sum += strategy * (realization_weight_p0 if player0_turn else realization_weight_p1)\n",
    "    \n",
    "    utility = np.zeros(NUM_ACTIONS)\n",
    "    node_utility = 0\n",
    "\n",
    "    for action in range(NUM_ACTIONS):\n",
    "        next_history = history + [action]\n",
    "        p0_weight = realization_weight_p0 if not player0_turn else strategy[action] * realization_weight_p0\n",
    "        p1_weight = realization_weight_p1 if player0_turn else strategy[action] * realization_weight_p1\n",
    "\n",
    "        utility[action] = -counter_factual_regret(nodes, cards, next_history, p0_weight, p1_weight)\n",
    "        node_utility += strategy[action] * utility[action]\n",
    "\n",
    "    node.regret_sum += (utility - node_utility) * (realization_weight_p1 if player0_turn else realization_weight_p0)\n",
    "    return node_utility\n",
    "\n",
    "def train(iterations):\n",
    "    cards = np.array([J, Q, K])\n",
    "    nodes = {}\n",
    "\n",
    "    utility = 0\n",
    "    for _ in range(iterations):\n",
    "        np.random.shuffle(cards)\n",
    "        utility += counter_factual_regret(nodes, cards[:2], [], 1, 1)\n",
    "\n",
    "    # Theoretical game optimal strategy\n",
    "    # https://en.wikipedia.org/wiki/Kuhn_poker#Optimal_strategy\n",
    "    print(\"Average game value:\", utility / iterations)\n",
    "    print(\"Theoretical nash equilibrium average game value:\", -1/18)\n",
    "    nodes = dict(sorted(nodes.items(), key=lambda item: [item[1].card] + [item[1].history]))\n",
    "    for n in nodes.values():\n",
    "        print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average game value: -0.05824832134121574\n",
      "Theoretical nash equilibrium average game value: -0.05555555555555555\n",
      "J [] ['PASS 76%', 'BET 24%']\n",
      "J ['PASS'] ['PASS 65%', 'BET 35%']\n",
      "J ['PASS', 'BET'] ['PASS 100%', 'BET 0%']\n",
      "J ['BET'] ['PASS 100%', 'BET 0%']\n",
      "Q [] ['PASS 99%', 'BET 1%']\n",
      "Q ['PASS'] ['PASS 100%', 'BET 0%']\n",
      "Q ['PASS', 'BET'] ['PASS 38%', 'BET 62%']\n",
      "Q ['BET'] ['PASS 67%', 'BET 33%']\n",
      "K [] ['PASS 19%', 'BET 81%']\n",
      "K ['PASS'] ['PASS 0%', 'BET 100%']\n",
      "K ['PASS', 'BET'] ['PASS 0%', 'BET 100%']\n",
      "K ['BET'] ['PASS 0%', 'BET 100%']\n"
     ]
    }
   ],
   "source": [
    "train(10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
